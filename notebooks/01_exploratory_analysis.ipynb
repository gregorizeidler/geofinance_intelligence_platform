{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# ğŸŒ Geo-Financial Intelligence Platform - Exploratory Analysis\n",
        "\n",
        "## Decoding the Spatial DNA of Financial Behavior\n",
        "\n",
        "This comprehensive analysis notebook demonstrates the power of spatial intelligence in financial technology applications. We'll build a complete geospatial data science pipeline that transforms location data into actionable financial insights.\n",
        "\n",
        "### ğŸ¯ Objectives\n",
        "1. **Spatial Feature Engineering**: Create 50+ geospatial features per location\n",
        "2. **Credit Risk Enhancement**: Improve risk assessment with spatial intelligence\n",
        "3. **Market Opportunity Analysis**: Identify optimal merchant acquisition targets\n",
        "4. **Interactive Visualization**: Create compelling spatial dashboards\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## ğŸ“¦ Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium\n",
        "from folium import plugins\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import xgboost as xgb\n",
        "import shap\n",
        "\n",
        "# Geospatial\n",
        "import h3\n",
        "import osmnx as ox\n",
        "from shapely.geometry import Point, Polygon\n",
        "\n",
        "# System\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Local imports\n",
        "from feature_engineering.hexgrid import HexagonalGrid, create_porto_alegre_grid\n",
        "from data_pipeline.data_sources import DataPipeline\n",
        "from feature_engineering.spatial_features import SpatialFeatureEngine, create_comprehensive_features\n",
        "from models.credit_risk_model import GeoCreditRiskModel, CreditRiskDataGenerator\n",
        "from models.merchant_acquisition import MarketOpportunityAnalyzer, MerchantAcquisitionOptimizer\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")\n",
        "print(f\"ğŸ“… Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ğŸ—ºï¸ Step 1: Hexagonal Grid Generation\n",
        "\n",
        "We start by creating an intelligent hexagonal grid system using H3 (Uber's Hierarchical Hexagons) for consistent spatial analysis across Porto Alegre's metropolitan area.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo: Complete Geo-Financial Intelligence Platform Pipeline\n",
        "print(\"ğŸŒ Running Geo-Financial Intelligence Platform Demo...\")\n",
        "\n",
        "# 1. Create hexagonal grid\n",
        "print(\"\\nğŸ”§ Step 1: Creating hexagonal grid system...\")\n",
        "hex_grid = create_porto_alegre_grid(resolution=9)\n",
        "grid_stats = hex_grid.get_grid_stats()\n",
        "print(f\"   âœ… Generated {grid_stats['total_hexagons']:,} hexagons covering {grid_stats['total_area_km2']:.0f} kmÂ²\")\n",
        "\n",
        "# 2. Run data pipeline\n",
        "print(\"\\nğŸ”„ Step 2: Running multi-source data integration...\")\n",
        "data_pipeline = DataPipeline()\n",
        "datasets = data_pipeline.run_full_pipeline()\n",
        "print(f\"   âœ… Integrated {len([d for d in datasets.values() if not d.empty])} datasets\")\n",
        "\n",
        "# 3. Generate comprehensive features\n",
        "print(\"\\nâš™ï¸ Step 3: Engineering spatial features...\")\n",
        "features_gdf = create_comprehensive_features(hex_grid, datasets)\n",
        "feature_count = len([col for col in features_gdf.columns if col not in ['hex_id', 'geometry', 'area_km2']])\n",
        "print(f\"   âœ… Generated {feature_count} spatial intelligence features\")\n",
        "\n",
        "# 4. Credit risk modeling\n",
        "print(\"\\nğŸ¤– Step 4: Training credit risk model...\")\n",
        "data_generator = CreditRiskDataGenerator(random_state=42)\n",
        "loans_df = data_generator.generate_synthetic_loan_data(features_gdf, n_loans_per_hex=3)\n",
        "credit_model = GeoCreditRiskModel()\n",
        "X, y = credit_model.prepare_training_data(features_gdf, loans_df)\n",
        "performance = credit_model.train_model(X, y)\n",
        "print(f\"   âœ… Model AUC: {performance['test_auc']:.3f} ({((performance['test_auc'] - 0.75) / 0.75) * 100:+.1f}% vs baseline)\")\n",
        "\n",
        "# 5. Market opportunity analysis\n",
        "print(\"\\nğŸª Step 5: Analyzing market opportunities...\")\n",
        "market_analyzer = MarketOpportunityAnalyzer()\n",
        "opportunity_analysis = market_analyzer.analyze_market_opportunities(features_gdf, datasets.get('merchants'))\n",
        "high_opp_count = (opportunity_analysis['opportunity_score'] >= 0.7).sum()\n",
        "print(f\"   âœ… Identified {high_opp_count:,} high-opportunity locations (avg ROI: {opportunity_analysis['expected_roi'].mean():.2f}x)\")\n",
        "\n",
        "# 6. Expansion optimization\n",
        "print(\"\\nğŸ’¼ Step 6: Optimizing expansion strategy...\")\n",
        "optimizer = MerchantAcquisitionOptimizer()\n",
        "optimization_results = optimizer.optimize_expansion_plan(opportunity_analysis, budget=500000)\n",
        "if 'error' not in optimization_results:\n",
        "    print(f\"   âœ… Optimized plan: {optimization_results['total_selected']} acquisitions, {optimization_results['average_roi']:.2f}x ROI\")\n",
        "else:\n",
        "    print(f\"   âš ï¸ Optimization: {optimization_results['error']}\")\n",
        "\n",
        "print(f\"\\nğŸ‰ Platform Demo Completed Successfully!\")\n",
        "print(f\"   ğŸ“Š Processed {len(features_gdf):,} locations with {feature_count} features each\")\n",
        "print(f\"   ğŸš€ Ready for production deployment in financial technology applications\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
